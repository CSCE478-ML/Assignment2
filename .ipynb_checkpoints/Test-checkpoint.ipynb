{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations_with_replacement\n",
    "import functools\n",
    "\n",
    "\n",
    "import assgn2 as asn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B # Q6, This following cell implements question #6, which is the first question in Part B: Data Processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('Dataset/winequality-red.csv',sep = ';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B # Q7: summarize  mean, standard deviation, and quartiles (For Report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.319637</td>\n",
       "      <td>0.527821</td>\n",
       "      <td>0.270976</td>\n",
       "      <td>2.538806</td>\n",
       "      <td>0.087467</td>\n",
       "      <td>15.874922</td>\n",
       "      <td>46.467792</td>\n",
       "      <td>0.996747</td>\n",
       "      <td>3.311113</td>\n",
       "      <td>0.658149</td>\n",
       "      <td>10.422983</td>\n",
       "      <td>5.636023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.741096</td>\n",
       "      <td>0.179060</td>\n",
       "      <td>0.194801</td>\n",
       "      <td>1.409928</td>\n",
       "      <td>0.047065</td>\n",
       "      <td>10.460157</td>\n",
       "      <td>32.895324</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.154386</td>\n",
       "      <td>0.169507</td>\n",
       "      <td>1.065668</td>\n",
       "      <td>0.807569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.990070</td>\n",
       "      <td>2.740000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.100000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.995600</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.996750</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.200000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.997835</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>1.003690</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    1599.000000       1599.000000  1599.000000     1599.000000   \n",
       "mean        8.319637          0.527821     0.270976        2.538806   \n",
       "std         1.741096          0.179060     0.194801        1.409928   \n",
       "min         4.600000          0.120000     0.000000        0.900000   \n",
       "25%         7.100000          0.390000     0.090000        1.900000   \n",
       "50%         7.900000          0.520000     0.260000        2.200000   \n",
       "75%         9.200000          0.640000     0.420000        2.600000   \n",
       "max        15.900000          1.580000     1.000000       15.500000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  1599.000000          1599.000000           1599.000000  1599.000000   \n",
       "mean      0.087467            15.874922             46.467792     0.996747   \n",
       "std       0.047065            10.460157             32.895324     0.001887   \n",
       "min       0.012000             1.000000              6.000000     0.990070   \n",
       "25%       0.070000             7.000000             22.000000     0.995600   \n",
       "50%       0.079000            14.000000             38.000000     0.996750   \n",
       "75%       0.090000            21.000000             62.000000     0.997835   \n",
       "max       0.611000            72.000000            289.000000     1.003690   \n",
       "\n",
       "                pH    sulphates      alcohol      quality  \n",
       "count  1599.000000  1599.000000  1599.000000  1599.000000  \n",
       "mean      3.311113     0.658149    10.422983     5.636023  \n",
       "std       0.154386     0.169507     1.065668     0.807569  \n",
       "min       2.740000     0.330000     8.400000     3.000000  \n",
       "25%       3.210000     0.550000     9.500000     5.000000  \n",
       "50%       3.310000     0.620000    10.200000     6.000000  \n",
       "75%       3.400000     0.730000    11.100000     6.000000  \n",
       "max       4.010000     2.000000    14.900000     8.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B # Q8: Shuffle the rows of data, using df.sample to shuffle without losing column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B # Q9: Generate Pair Plots using seaborn package. Used to identify and report redundant features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# Matplotlib and seaborn for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# Calculate correlation coefficient\n",
    "def corrfunc(x, y, **kws):\n",
    "    r, _ = stats.pearsonr(x, y)\n",
    "    ax = plt.gca()\n",
    "    ax.annotate(\"r = {:.2f}\".format(r),\n",
    "                xy=(.1, .6), xycoords=ax.transAxes,\n",
    "               size = 24)\n",
    "    \n",
    "cmap = sns.cubehelix_palette(light=1, dark = 0.1,\n",
    "                             hue = 0.5, as_cmap=True)\n",
    "\n",
    "sns.set_context(font_scale=2)\n",
    "\n",
    "# Pair grid set up\n",
    "g = sns.PairGrid(df)\n",
    "\n",
    "# Scatter plot on the upper triangle\n",
    "g.map_upper(plt.scatter, s=10, color = 'red')\n",
    "\n",
    "# Distribution on the diagonal\n",
    "g.map_diag(sns.distplot, kde=False, color = 'red')\n",
    "\n",
    "# Density Plot and Correlation coefficients on the lower triangle\n",
    "g.map_lower(sns.kdeplot, cmap = cmap)\n",
    "g.map_lower(corrfunc);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = 'quality') #data matrix\n",
    "y = df['quality']  #quality\n",
    "\n",
    "X = np.array(X)  # to np array \n",
    "y = np.array(y)   # to np array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features = ['volatile acidity', 'density', 'pH', 'sulphates', 'alcohol']\n",
    "best_df = df[best_features]\n",
    "X = np.array(best_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_trainTest(X,y,t):\n",
    "    train_size = int((1-t) * X.shape[0])   \n",
    "    return X[:train_size],X[train_size:],y[:train_size],y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_trainTest(X,y,t=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (X_train - np.mean(X_train))/np.std(X_train)\n",
    "X_test = (X_test - np.mean(X_test))/np.std(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A Question #1: Implement asn.polynomialFeatures function to generate polynomial and interaction features for a given degree of the polynomial.\n",
    "# Part A Question #2: Implement the function asn.mse to calculate and return the mean squared error of two vectors. The following cell includes the first implementation of this in our test script.\n",
    "\n",
    "# Part A Question #5: Implementation of the Linear_Regression Model Class. Initial initialization of this is done in the following cell.\n",
    "\n",
    "# Part C Question #10, steps a-e are done in this cell, and the next is where the optimal values are placed. This question is why the other questions are tested at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = asn.polynomialFeatures(X_train,1)\n",
    "x_test = asn.polynomialFeatures(X_test,1)\n",
    "validation_accuracy = np.empty((4,6,2))\n",
    "lambd= [1.0, 0,0.1,0.01, 0.001, 0.0001]\n",
    "learning_rate = [0.1, 0.01, 0.001, 0.001]\n",
    "regularizer= ['l1', 'l2']\n",
    "minScore = 1e10\n",
    "for i,lr in enumerate(learning_rate):\n",
    "    for j,ld in enumerate(lambd):\n",
    "        for x,rg in enumerate(regularizer):\n",
    "            lnreg = asn.Linear_Regression()\n",
    "            model_args = {'learning_rate' : lr,'lambd':ld,'regularizer' : rg,'epochs' : 1000, 'tol' : 1e-3}\n",
    "            result = asn.sFold(5,x_train,y_train,lnreg,error_fuction = asn.mse,**model_args)\n",
    "            validation_accuracy[i,j,x] = result['Average error']\n",
    "            if validation_accuracy[i,j,x] < minScore:\n",
    "                minScore = validation_accuracy[i,j,x]\n",
    "                index = [i,j,x]\n",
    "            \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(index)\n",
    "a,b,c = index\n",
    "print('optimal learning_rate: ',learning_rate[a])\n",
    "print('optimal lambd: ',lambd[b])\n",
    "print('optimal regularizer: ',regularizer[c])\n",
    "print('optimal value',validation_accuracy[a,b,c])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part C Question #15: The Stochastic Gradient Descent Linear Regression algorithm is used, as asn.SGD(). This is the first usage of this function in this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "validation_accuracy = np.empty((4,6,2))\n",
    "lambd= [1.0, 0,0.1,0.01, 0.001, 0.0001]\n",
    "learning_rate = [0.1, 0.01, 0.001, 0.001]\n",
    "regularizer= ['l1', 'l2']\n",
    "minScore = 1e10\n",
    "for i,lr in enumerate(learning_rate):\n",
    "    for j,ld in enumerate(lambd):\n",
    "        for x,rg in enumerate(regularizer):\n",
    "            lnreg = asn.SGD()\n",
    "            model_args = {'learning_rate' : lr,'lambd':ld,'regularizer' : rg,'epochs' : 1000,'tol' : 1e-3}\n",
    "            result = asn.sFold(5,x_train,y_train,lnreg,error_fuction = asn.mse,**model_args)\n",
    "            validation_accuracy[i,j,x] = result['Average error']\n",
    "            if validation_accuracy[i,j,x] < minScore:\n",
    "                minScore = validation_accuracy[i,j,x]\n",
    "                index = [i,j,x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(index)\n",
    "a,b,c = index\n",
    "print('optimal learning_rate: ',learning_rate[a])\n",
    "print('optimal lambd: ',lambd[b])\n",
    "print('optimal regularizer: ',regularizer[c])\n",
    "print('optimal value',validation_accuracy[a,b,c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A Question #5: Implementation of the Linear_Regression Model Class. Part a) is tested, with the Linear_Regression.fit function, which implements batch gradient descent algorithm. Part b) is also tested with the Linear_Regression.predict function, which returns the 1d array of prediction for each row in \"X\".\n",
    "\n",
    "# Part C Question #11, the model is evaluated on our test data, with the standard Linear Regression to find mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "linRg = asn.Linear_Regression()\n",
    "linRg.fit(x_train,y_train,learning_rate=0.1,epochs=1000,regularizer='l1',lambd= 0., tol=1e-3)\n",
    "\n",
    "y_test_predicted = linRg.predict(x_test)\n",
    "print(\"Test: Mean squared error: %.2f\"\n",
    "      % asn.mse(y_test, y_test_predicted)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part C Question #15 extra credit, model is evaluated with stochastic gradient descent linear regression, and the mse is reported. Because the Mean Squared Error is smaller than for the the batch gradient descent algorithm, the SGD seems to be the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "linRg2 = asn.SGD()\n",
    "linRg2.fit(x_train,y_train,learning_rate=0.1,epochs=1000,regularizer='l2',lambd= 0.001, tol=1e-3)\n",
    "\n",
    "y_test_predicted_sgd = linRg2.predict(x_test)\n",
    "print(\"Test: Mean squared error: %.2f\"\n",
    "      % asn.mse(y_test, y_test_predicted_sgd)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = 5\n",
    "train_size = 100  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A Question #3: Implement the asn.learning_curve function, which computes training and validation errors, an dreturns two arrays containing training and validation rmse values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing learning curve function\n",
    "train_scores, val_scores, train_sizes,_ = asn.learning_curve(asn.Linear_Regression, x_train, y_train, cv, train_size = train_size, learning_rate = 0.1, \n",
    "               epochs = 1000, tol = 1e-5, regularizer = 'l1', lambd = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part C Question #12: The learning_curve function is used to help create the rmse values, and in the following cell, the learning curve is plotted using our best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create means and standard deviations of training set scores\n",
    "train_mean = np.mean(train_scores)\n",
    "train_std = np.std(train_scores)\n",
    "\n",
    "# Create means and standard deviations of validation set scores\n",
    "val_mean = np.mean(val_scores)\n",
    "val_std = np.std(val_scores)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, train_scores, \"r-+\", linewidth=3, label=\"Training Score\")\n",
    "plt.plot(train_sizes, val_scores, \"b-\", linewidth=2, label=\"Cross-validation Score\")\n",
    "plt.legend(loc=\"best\", fontsize=14)   \n",
    "plt.xlabel(\"Training set size\", fontsize=14) \n",
    "plt.ylabel(\"RMSE\", fontsize=14) \n",
    "plt.title(\"Learning Curve (Linear Model)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part C Question #13: The following 5 cells are used to determine the best hyperparameter values for the training data matrix with a polynomial degree 3, and the learning curve is plot using the rmse values from the learning_curve function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3_train = asn.polynomialFeatures(X_train,3)\n",
    "x3_test = asn.polynomialFeatures(X_test,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = asn.Linear_Regression()\n",
    "model.fit(x3_train,y_train,learning_rate=0.01,epochs=1000,regularizer='l2',lambd= 15, tol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_train_predicted = model.predict(x3_train)\n",
    "print(y_train_predicted)\n",
    "y_test_predicted = model.predict(x3_test)\n",
    "print(\"Training: Mean squared error: %.2f\"\n",
    "      % asn.mse(y_train, y_train_predicted))\n",
    "\n",
    "print(\"Test: Mean squared error: %.2f\"\n",
    "      % asn.mse(y_test, y_test_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing learning curve function\n",
    "train_scores3, val_scores3, train_sizes3,_ = asn.learning_curve(asn.Linear_Regression, x3_train, y_train, cv, train_size = train_size, learning_rate = 0.01, \n",
    "               epochs = 1000, tol = 1e-3, regularizer = 'l2', lambd = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create means and standard deviations of training set scores\n",
    "train_mean = np.mean(train_scores3)\n",
    "train_std = np.std(train_scores3)\n",
    "\n",
    "# Create means and standard deviations of validation set scores\n",
    "val_mean = np.mean(val_scores3)\n",
    "val_std = np.std(val_scores3)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes3, train_scores3, \"r-+\", linewidth=3, label=\"Training Score\")\n",
    "plt.plot(train_sizes3, val_scores3, \"b-\", linewidth=2, label=\"Cross-validation Score\")\n",
    "plt.legend(loc=\"best\", fontsize=14)   \n",
    "plt.xlabel(\"Training set size\", fontsize=14) \n",
    "plt.ylabel(\"RMSE\", fontsize=14) \n",
    "plt.title(\"Learning Curve (Linear Model)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A Question #4: Implement asn.plot_polynomial_model_complexity function, which plots training and validation rmse values of the data matrix X for polynomial degrees from 1 up to maxPolynomialDegree.\n",
    "\n",
    "# Part C Question #14: The implemented plot_polynomial_model_complexity function is used to plot the rmse values for the training and validation folds for polynomial degrees 1-5. The previous training data is used as the input for this function, and hte hyperparameter values are chosen judiciously so as to work with the higher-degree models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxPolynomialDegree = 5\n",
    "asn.plot_polynomial_model_complexity(asn.Linear_Regression, X_train, y_train, cv, maxPolynomialDegree, \n",
    "                                     learning_rate=0.1, epochs=1000, tol=1e-3, regularizer=None, lambd=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = asn.polynomialFeatures(X_train,1)\n",
    "x_test = asn.polynomialFeatures(X_test,1)\n",
    "linRg = asn.Linear_Regression()\n",
    "linRg.fit(x_train,y_train,learning_rate=0.1,epochs=1000,regularizer='l1',lambd= 0., tol=1e-3)\n",
    "\n",
    "y_test_predicted_sgd = linRg.predict(x_test)\n",
    "print(\"Test: Mean squared error: %.2f\"\n",
    "      % asn.mse(y_test, y_test_predicted_sgd)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linRg.theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linRg2 = asn.Linear_Regression()\n",
    "linRg2.fit(x_train,y_train,learning_rate=0.01,epochs=1000,regularizer='l1',lambd= 0., tol=1e-3)\n",
    "\n",
    "y_test_predicted_sgd = linRg2.predict(x_test)\n",
    "print(\"Test: Mean squared error: %.2f\"\n",
    "      % asn.mse(y_test, y_test_predicted_sgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linRg2.theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = asn.polynomialFeatures(X_train,1)\n",
    "x_test = asn.polynomialFeatures(X_test,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "linRg3 = asn.SGD()\n",
    "linRg3.fit(x_train,y_train,learning_rate=0.1,epochs=1000,regularizer='l2',lambd= 0.001, tol=1e-3)\n",
    "\n",
    "y_test_predicted_sgd = linRg3.predict(x_test)\n",
    "print(\"Test: Mean squared error: %.2f\"\n",
    "      % asn.mse(y_test, y_test_predicted_sgd)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linRg3.theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "linRg5 = asn.SGD()\n",
    "linRg5.fit(x_train,y_train,learning_rate=0.01,epochs=1000,regularizer='l2',lambd= 0.001, tol=1e-3)\n",
    "\n",
    "y_test_predicted_sgd = linRg5.predict(x_test)\n",
    "print(\"Test: Mean squared error: %.2f\"\n",
    "      % asn.mse(y_test, y_test_predicted_sgd)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linRg5.theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "linRg4 = asn.SGD()\n",
    "linRg4.fit(x_train,y_train,learning_rate=0.001,epochs=1000,regularizer='l2',lambd= 0.001, tol=1e-3)\n",
    "\n",
    "y_test_predicted_sgd = linRg4.predict(x_test)\n",
    "print(\"Test: Mean squared error: %.2f\"\n",
    "      % asn.mse(y_test, y_test_predicted_sgd)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linRg4.theta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
